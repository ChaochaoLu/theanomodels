# MLP Example

* This will run a simple baseline model, a model with batch-normalization[1], and a model with layer-normalization[2].
* To run, execute command `python example.py`.  This will run a series of 6 experiments sequentially and output the results into a new directory `output`.
* To view results, see `example-results.ipynb`.

[1] Ioffe, Sergey, and Christian Szegedy. "Batch normalization: Accelerating deep network training by reducing internal covariate shift." arXiv preprint arXiv:1502.03167 (2015). http://arxiv.org/abs/1502.03167

[2] Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. "Layer Normalization." arXiv preprint arXiv:1607.06450 (2016). http://arxiv.org/abs/1607.06450
